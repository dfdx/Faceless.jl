
Boltzmann.jl commit 343fce064c162a62215af7c1be07eea5b5bc2762
resize ratio = 0.5 (~12k visible variables)

Experiment 1: all good, but only 2 different faces (similar as well)
more gibbs steps gives slightly better results
    #for n_gibbs in [1, 3, 5]
    #    println("-------- n_gibbs = $n_gibbs -----------")
    #    rbm = RBM(Degenerate, Bernoulli, size(dataset, 1), 1024, sigma=0.001)
    #    @time fit(rbm, dataset, n_gibbs=n_gibbs, lr=0.01,
    #              batch_size=1000, n_epochs=100)
    #    nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
    #end


Experiment 2: sigma=0.1 - high distortion, sigma=0.01 - medium distortion, sigma=0.001 - no distortion
all very similar
    #for sigma in [0.001, 0.01, 0.1]
    #    println("-------- sigma = $sigma -----------")
    #    rbm = RBM(Degenerate, Bernoulli, size(dataset, 1), 1024, sigma=sigma)
    #    @time fit(rbm, dataset, n_gibbs=3, lr=0.01,
    #              batch_size=1000, n_epochs=100)
    #    nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
    #end


Experiment 3: sigma=0.5 - total shit, 100% distorsion
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1), 1024, sigma=0.5)
#        @time fit(rbm, dataset, n_gibbs=3, lr=0.01,
#                  batch_size=1000, n_epochs=100)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])


Experiment 4: lr=0.001 and lr=0.01 - almost useless (pure noise), lr=0.1 and lr=1 - better (or vice versa?)
    #for lr in [0.001, 0.01, 0.1, 1.]
    #    println("-------- lr = $lr -----------")
    #    rbm = RBM(Degenerate, Bernoulli, size(dataset, 1), 1024, sigma=0.1)
    #    @time fit(rbm, dataset, n_gibbs=3, lr=lr,
    #              batch_size=1000, n_epochs=100)
    #    nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
    #end

!!! Experiment 5: many similar, but in general quite good
#rbm = RBM(Degenerate, Bernoulli, size(dataset, 1), 1024, sigma=0.001)
#@time fit(rbm, dataset, n_gibbs=3, lr=0.001,
#          batch_size=1000, n_epochs=100)
#nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])


Experiment 6: n_gibbs > 1 doesn't make any difference
#for (i, p) in enumerate([1, 3, 5])
#        println("-------- parameter = $p -----------")
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1), 1024, sigma=0.001)
#        @time fit(rbm, dataset, n_gibbs=p, lr=0.001,
#                  batch_size=1000, n_epochs=100)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37:72])
#        rbms[i] = rbm
#    end


Experiment 7: L1 weight decay gives very high distortion for all
values of parameters. In addition, score is unstable and much higher
(-8k..-9k vs. normal -7k)
#for (i, p) in enumerate([.5, .7, .9])
#        println("-------- parameter = $p -----------")
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1), 1024, sigma=0.001)
#        @time fit(rbm, dataset, n_gibbs=1, lr=0.001,
#                  batch_size=1000, n_epochs=100,
#                  weight_decay_kind=:l1, weight_decay_rate=p)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37+36:72+46])
#        rbms[i] = rbm
#    end


Experiment 8: L2 weight decay gives very good smoothing
wd_rate=0.5 - excellent smoothing (still quite similar)
wd_rate=0.9 - faces are less natural
    #rbms = Array(Any, 3)
    #for (i, p) in enumerate([.5])
    #    println("-------- parameter = $p -----------")
    #    rbm = RBM(Degenerate, Bernoulli, size(dataset, 1),
    #                  1024, sigma=0.001)
    #    @time fit(rbm, dataset, n_gibbs=1, lr=0.001,
    #              batch_size=1000, n_epochs=10,
    #              weight_decay_kind=:l2, weight_decay_rate=p)
    #    nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
    #    nviewall([to_image(rbm.W'[:, i], mask) for i=37+36:72+46])
    #    rbms[i] = rbm
    #end
    #readline(STDIN)


Experiment 9:
1) wd_rate=.1, sigma=.001 - all similar, just some with higher contrast,
 others with very little contrast
2) wd_rate=.3, sigma=.001 - all similar, black and white
3) wd_rate=.5, sigma=.001 - all similar
4) wd_rate=.9, sigma=.001 - all similar, "dirty" faces
5) wd_rate=.1, sigma=.01 - same as (1)
6) wd_rate=.3, sigma=.01 - same as (2)
7) wd_rate=.5, sigma=.01 - all similar
8) wd_rate=.9, sigma=.01 - all similar, "dirty" faces
#    rbms = Array(Any, 8)
#    for (i, (p1, p2)) in enumerate([(.1, .001), (.3, .001),
#                                  (.5, .001), (.9, .001),
#                                  (.1, .01), (.3, .01)
#                                  (.5, .01), (.9, .01)
#                                    ])
#        println("-------- param1 = $p1, param2 = $p2 -----------")
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1),
#                      1024, sigma=p2)
#        @time fit(rbm, dataset, n_gibbs=1, lr=0.001,
#                  batch_size=1000, n_epochs=20,
#                  weight_decay_kind=:l2, weight_decay_rate=p1)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37:72])
#        rbms[i] = rbm
#    end


Experiment 10: learning rate with improved L2 regularization
1) lr=0.01 - good quality, at least 3 distinct faces
2,3) lr=0.1 & lr=1 - high distortion
#    for (i, p1) in enumerate([0.01, 0.1, 1.0])
#        println("-------- param1 = $p1 -----------")
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1),
#                      1024, sigma=0.01)
#        @time fit(rbm, dataset, n_gibbs=1, lr=p1,
#                  batch_size=1000, n_epochs=20,
#                  weight_decay_kind=:l2, weight_decay_rate=0.5)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37:72])
#        rbms[i] = rbm
#    end

Experiment 11: Gaussian visible units - high distortion

Experiment 12: Bernolli visible units - distortion lower than with
Gaussian, many DIFFERENT faces
#    rbms = Array(Any, 8)
#    for (i, p1) in enumerate([0.001])
#        println("-------- param1 = $p1 -----------")
#        rbm = RBM(Bernoulli, Bernoulli, size(dataset, 1),
#                      1024, sigma=0.01)
#        @time fit(rbm, dataset, n_gibbs=1, lr=p1,
#                  batch_size=1000, n_epochs=20,
#                  weight_decay_kind=:l2, weight_decay_rate=0.5)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37:72])
#        rbms[i] = rbm
#    end


Experiment 13: Faces are smooth, different
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1),
#                      1024, sigma=0.01)
#        @time fit(rbm, dataset, n_gibbs=1, lr=p1,
#                  batch_size=1000, n_epochs=20,
#                  weight_decay_kind=:l2, weight_decay_rate=0.5)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])


Experiment 14: sparsity target - many different
#for (i, p) in enumerate([0.001, 0.01, 0.1])
#        println("-------- param1 = $p -----------")
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1),
#                      1024, sigma=0.01)
#        @time fit(rbm, dataset, n_gibbs=1, lr=0.01,
#                  batch_size=1000, n_epochs=20,
#                  weight_decay_kind=:l2, weight_decay_rate=0.5,
#                  sparsity_cost=0.1, sparsity_target=p)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37:72])
#        rbms[i] = rbm
#    end


Experiment 15: sparsity cost - see images
#rbms = Array(Any, 8)
#    for (i, p) in enumerate([0.01, 0.1, 0.5, 0.9])
#        println("-------- param1 = $p -----------")
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1),
#                      1024, sigma=0.01)
#        @time fit(rbm, dataset, n_gibbs=1, lr=0.01,
#                  batch_size=1000, n_epochs=20,
#                  weight_decay_kind=:l2, weight_decay_rate=0.5,
#                  sparsity_cost=p, sparsity_target=.001)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37:72])
#        rbms[i] = rbm
#    end


Experiment 16: n_vis
512 - something good
1024 - good
2048 - just funny
#for (i, p) in enumerate([36, 64, 128, 256, 512, 1024, 2048])
#        println("-------- param1 = $p -----------")
#        rbm = RBM(Degenerate, Bernoulli, size(dataset, 1),
#                  p, sigma=0.01)
#        @time fit(rbm, dataset, n_gibbs=1, lr=0.01,
#                  batch_size=1000, n_epochs=20,
#                  weight_decay_kind=:l2, weight_decay_rate=0.5,
#                  sparsity_cost=0.1, sparsity_target=0.01)
#        nviewall([to_image(rbm.W'[:, i], mask) for i=1:36])
#        # nviewall([to_image(rbm.W'[:, i], mask) for i=37:72])
#        rbms[i] = rbm
#    end


pseudo-likelihood progress (number of iterations - likelihood)
40 - 9471
50 - 9426

some results from previous experiments
n_hid=192, n_gibbs=3, n_meta=10 ~ 7 faces of good quality
n_hid=192, n_gibbs=5, n_meta=10 ~ 4 faces of good quality
n_hid=256, n_gibbs=1, n_meta=10 ~ no faces at all
n_hid=256, n_gibbs=3, n_meta=10 ~ 10 faces of almost good quality
n_hid=256, n_gibbs=5, n_meta=10 ~ 11 faces of almost good quality
n_hid=256, n_gibbs=10, n_meta=10 ~ 11 faces of almost good quality
n_hid=256, n_gibbs=5, n_meta=20 ~ 12 faces of almost good quality
n_hid=128, n_gibbs=3, n_meta=10 ~ all faces of bad quality
n_hid=192, n_gibbs=3, n_meta=10 ~ 3 faces of a modate quality
n_hid=256, n_gibbs=3, n_meta=10 ~ 10 faces of moderate quality
n_hid=320, n_gibbs=3, n_meta=10 ~ 16 faces of almost good qualiy
n_hid=384, n_gibbs=3, n_meta=10 ~ 17 faces of almost good qualiy
n_hid=512, n_gibbs=3, n_meta=10 ~ 22 faces of different quality
n_hid=768, n_gibbs=3, n_meta=10 ~ 25 faces of different quality
n_hid=1024, n_gibbs=3, n_meta=10 ~ 21 face of different quality
n_hid=768, n_gibbs=3, n_meta=10, sigma=0.001 ~ almost all faces!
n_hid=512, n_gibbs=3, n_meta=10, sigma=0.001 ~ all good, but many similar
n_hid=1024, n_gibbs=3, n_meta=10, sigma=0.001 ~ all good
n_hid=128, n_gibbs=3, n_meta=10, lr=0.01 ~ 1 good, others similar and bad
n_hid=128, n_gibbs=10, n_meta=10, lr=0.01 ~ 1 good, others similar and bad
brbm: n_hid=768, n_gibbs=3, n_meta=10, lr=0.01 ~ 20 good
grbm: n_hid=1024, n_gibbs=3, n_meta=10 ~ half almost good
grbm: n_hid=768, n_gibbs=3, n_meta=10 ~ half almost good
grbm: n_hid=1024, n_gibbs=10, n_meta=10 ~ half almost good
grbm: n_hid=1024, n_gibbs=10, n_meta=3, lr=0.01 ~ half almost good
#! grbm: n_hid=1024, n_gibbs=3, n_meta=10, sigma=0.001, lr=0.01 ~ all really good!
brbm: n_hid=1024, n_gibbs=3, n_meta=10, sigma=0.001, lr=0.01 ~ almost the same

grbm (w/ momentum): n_hid=1024, n_gibbs=2, n_meta=5, sigma=0.001, lr=0.01 ~ 2243
